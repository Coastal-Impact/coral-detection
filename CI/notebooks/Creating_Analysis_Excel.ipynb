{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "s4myWn-uuoVB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Stuff\n",
        "* Installing libraries\n",
        "* Importing libraries\n",
        "* Defining functions"
      ],
      "metadata": {
        "id": "vle-ajhOAFYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install XlsxWriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iIW4ft3r222",
        "outputId": "ebdf2fe9-17e8-4d04-8377-08e5a1a08749"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: XlsxWriter in /usr/local/lib/python3.10/dist-packages (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing libraries and all\n",
        "import openpyxl\n",
        "import xlsxwriter\n",
        "import pathlib\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import os.path\n",
        "import base64\n",
        "import io\n",
        "from io import BytesIO\n",
        "from urllib.request import urlopen\n",
        "import re\n",
        "import glob\n",
        "from PIL import Image, ImageDraw, ImageOps\n",
        "\n",
        "ALL_DATE_NAMES = [\"23.2.6\", \"22.12.7\", \"23.2.28\", \"23.4.9\", \"23.1.6\", \"23.5.5\"]\n",
        "# ALL_DATE_NAMES = ['23.2.6']\n",
        "\n",
        "def add_information_for_specific_table(table_name, table_address, date_name, table_information_dict, save_file_address, worksheet_name):\n",
        "  all_images = []\n",
        "  all_image_names = []\n",
        "  coco_file_found = False\n",
        "\n",
        "  table_folder_address = os.path.join(table_address, \"*\")\n",
        "  specific_table_content = list(glob.iglob(table_folder_address))\n",
        "  for item_address in specific_table_content:\n",
        "      potential_image = re.findall(\".*jpg|png|JPG|PNG\", item_address)\n",
        "      if len(potential_image)>0:\n",
        "          image_name = item_address.split(\"/\")[-1]\n",
        "          all_image_names.append(image_name)\n",
        "\n",
        "          # download image\n",
        "          image = Image.open(item_address)\n",
        "          image = ImageOps.exif_transpose(image)\n",
        "          all_images.append(image)\n",
        "\n",
        "      elif (item_address.split(\"/\")[-1].lower() == 'output'):\n",
        "          coco_file_found, coco_file = search_for_coco(item_address)\n",
        "\n",
        "          if coco_file_found:\n",
        "              print(\"COCO file found\")\n",
        "              bool_cat = check_categories(coco_file)\n",
        "              if not bool_cat:\n",
        "                  print(\"Didn't find correct categories in COCO file\")\n",
        "          else:\n",
        "              print(\"COCO file not found\")\n",
        "\n",
        "  # sorting image names and images\n",
        "  sorting_order = np.argsort(all_image_names)\n",
        "  all_image_names = np.array(all_image_names)[sorting_order]\n",
        "  all_images = sort_images(all_images, sorting_order)\n",
        "\n",
        "\n",
        "  main_dict = initialise_main_dict()\n",
        "\n",
        "  # going into each image\n",
        "  try:\n",
        "      for idx, current_image_name in enumerate(all_image_names):\n",
        "          current_image_id = get_id(coco_file, current_image_name)\n",
        "          current_bboxes, current_segs, current_classes, current_areas = get_coco_annotations_for_image_id(coco_file, current_image_id)\n",
        "\n",
        "          if not (\"ref\" in [i.lower() for i in current_classes]):\n",
        "              print(f\"No ref label found\")\n",
        "              break\n",
        "\n",
        "          current_bboxes = change_bboxes(current_bboxes)\n",
        "          without_mask_images, with_mask_images, areas = get_final_images_and_area(all_images[idx],\n",
        "                                                                                    current_bboxes,\n",
        "                                                                                    current_segs,\n",
        "                                                                                    current_classes,\n",
        "                                                                                    current_areas)\n",
        "          resize_images(with_mask_images)\n",
        "          resize_images(without_mask_images)\n",
        "          for final_idx, _ in enumerate(current_classes):\n",
        "              main_dict['date'].append(date_name)\n",
        "              main_dict['table'].append(table_name)\n",
        "              main_dict['tile'].append(idx+1)\n",
        "              main_dict['name'].append(current_classes[final_idx])\n",
        "              main_dict['without_mask'].append(without_mask_images[final_idx])\n",
        "              main_dict['with_mask'].append(with_mask_images[final_idx])\n",
        "              main_dict['area'].append(areas[final_idx])\n",
        "\n",
        "      table_number = int(re.findall(\"\\d+\", table_name)[0])\n",
        "\n",
        "      last_row = table_information_dict[table_number][\"last_row\"]\n",
        "      last_row = main_dict_to_excel_openpyxl(main_dict,\n",
        "                                             last_row,\n",
        "                                             save_file_address,\n",
        "                                             worksheet_name)\n",
        "      table_information_dict[table_number][\"last_row\"] = last_row\n",
        "\n",
        "  except Exception as e:\n",
        "        print(\"\\nERROR:\", e, \"\\n\")\n",
        "  return None\n",
        "\n",
        "def read_coco_file(coco_file_address):\n",
        "    open_file = open(coco_file_address)\n",
        "    coco_file = json.load(open_file)\n",
        "    return coco_file\n",
        "\n",
        "# def search_for_coco_in_annotation_output(item_address):\n",
        "#   coco_file_found = False\n",
        "#   coco_file = None\n",
        "\n",
        "#   output_content = list(glob.iglob(file_address+\"/*\"))\n",
        "#   if len(output_content==0):\n",
        "#       return coco_file_found, coco_file\n",
        "\n",
        "#   for item_address in output_content:\n",
        "#       if (item_address.split(\"/\")[-1].lower() == 'output'):\n",
        "#           coco_file_found, coco_file = search_for_coco(item_address)\n",
        "\n",
        "#   return coco_file_found, coco_file\n",
        "\n",
        "def search_for_coco(file_address):\n",
        "    output_content = list(glob.iglob(file_address+\"/*\"))\n",
        "    annotation_output = [i for i in output_content if i.split(\"/\")[-1].lower() == 'annotation output']\n",
        "    if len(annotation_output)>0:\n",
        "        output_content = list(glob.iglob(os.path.join(annotation_output[0], \"*\")))\n",
        "    try:\n",
        "        coco_file = [i for i in output_content if \"coco\" in i.split(\"/\")[-1].lower()]\n",
        "        coco_file_found = True\n",
        "        coco_file = read_coco_file(coco_file[0])\n",
        "    except:\n",
        "        coco_file_found = False\n",
        "        coco_file = None\n",
        "    return coco_file_found, coco_file\n",
        "\n",
        "def initialise_main_dict():\n",
        "    main_dict = {\n",
        "      'date':[],\n",
        "      'table':[],\n",
        "      'tile':[],\n",
        "      'name':[],\n",
        "      'without_mask':[],\n",
        "      'with_mask':[],\n",
        "      'area':[]\n",
        "    }\n",
        "    return main_dict\n",
        "\n",
        "def write_initial_header(name_of_file, worksheet_name):\n",
        "    file_path = f\"{name_of_file}.xlsx\"\n",
        "    if os.path.exists(file_path):\n",
        "        wb = openpyxl.load_workbook(file_path)\n",
        "        wb.create_sheet(worksheet_name)\n",
        "        ws = wb[worksheet_name]\n",
        "\n",
        "        ws.cell(row=1 , column=1).value=\"Date\"\n",
        "        ws.cell(row=1 , column=2).value=\"Table\"\n",
        "        ws.cell(row=1 , column=3).value=\"Tile\"\n",
        "        ws.cell(row=1 , column=4).value=\"Name\"\n",
        "        ws.cell(row=1 , column=5).value=\"Original\"\n",
        "        ws.cell(row=1 , column=6).value=\"With Mask\"\n",
        "        ws.cell(row=1 , column=7).value=\"Area\"\n",
        "\n",
        "        wb.save(file_path)\n",
        "\n",
        "        wb.close()\n",
        "    else:\n",
        "        # use existing xlsx code\n",
        "        workbook = xlsxwriter.Workbook(file_path)\n",
        "        worksheet = workbook.add_worksheet(worksheet_name)\n",
        "\n",
        "        worksheet.write(0, 0, \"Date\")\n",
        "        worksheet.write(0, 1, \"Table\")\n",
        "        worksheet.write(0, 2, \"Tile\")\n",
        "        worksheet.write(0, 3, \"Name\")\n",
        "        worksheet.write(0, 4, \"Original\")\n",
        "        worksheet.write(0, 5, \"With Mask\")\n",
        "        worksheet.write(0, 6, \"Area\")\n",
        "\n",
        "        workbook.close()\n",
        "\n",
        "\n",
        "def main_dict_to_excel_openpyxl(main_dict, last_row, name_of_file, worksheet_name):\n",
        "    file_path = f'{name_of_file}.xlsx'\n",
        "    wb = openpyxl.load_workbook(file_path)\n",
        "    ws = wb[worksheet_name]\n",
        "\n",
        "    number_entries = len(main_dict[\"date\"])\n",
        "\n",
        "    for row_number in range(2, number_entries+2):\n",
        "        for col_number, title in enumerate(main_dict.keys(), start=1):\n",
        "            value = main_dict[title][row_number-2]\n",
        "            if title in [\"date\", 'table', 'tile', 'name', 'area']:\n",
        "                ws.cell(row=row_number+last_row, column=col_number).value = value\n",
        "            else:\n",
        "                img_byte_arr = io.BytesIO()\n",
        "                value.save(img_byte_arr, format='png')\n",
        "                img = Image.open(img_byte_arr)\n",
        "                img = openpyxl.drawing.image.Image(img)\n",
        "                img.height = 20\n",
        "                img.width = 64\n",
        "                img.anchor = chr(64+col_number) + str(row_number+last_row)\n",
        "                ws.add_image(img)\n",
        "    wb.save(file_path)\n",
        "    last_row += number_entries\n",
        "    return last_row\n",
        "\n",
        "\n",
        "def main_dict_to_excel_xls(main_dict):\n",
        "    workbook = xlsxwriter.Workbook(\"Analysis-Excel.xlsx\")\n",
        "    worksheet = workbook.add_worksheet()\n",
        "    number_entries = len(main_dict[\"date\"])\n",
        "\n",
        "    # image-related definitions\n",
        "    cell_width = 64.0\n",
        "    cell_height = 20.0\n",
        "\n",
        "    image_width, image_height = main_dict[\"without_mask\"][0].size\n",
        "\n",
        "    x_scale = cell_width/image_width\n",
        "    y_scale = cell_height/image_height\n",
        "\n",
        "\n",
        "\n",
        "    for row_number in range(1, number_entries+1):\n",
        "        for col_number, title in enumerate(main_dict.keys()):\n",
        "            value = main_dict[title][row_number-1]\n",
        "            if title==\"date\":\n",
        "                worksheet.write(row_number, col_number, value)\n",
        "            elif title==\"table\":\n",
        "                worksheet.write(row_number, col_number, value)\n",
        "            elif title==\"tile\":\n",
        "                worksheet.write(row_number, col_number, value)\n",
        "            elif title==\"name\":\n",
        "                worksheet.write(row_number, col_number, value)\n",
        "            elif title==\"without_mask\":\n",
        "                img_byte_arr = io.BytesIO()\n",
        "                value.save(img_byte_arr, format='PNG')\n",
        "                image_data = img_byte_arr\n",
        "                worksheet.insert_image(row_number, col_number, 'random.png', {\"image_data\": image_data, 'x_scale': x_scale, 'y_scale': y_scale})\n",
        "            elif title==\"with_mask\":\n",
        "                img_byte_arr = io.BytesIO()\n",
        "                value.save(img_byte_arr, format='PNG')\n",
        "                image_data = img_byte_arr\n",
        "                worksheet.insert_image(row_number, col_number, 'random.png', {\"image_data\": image_data, 'x_scale': x_scale, 'y_scale': y_scale})\n",
        "            elif title==\"area\":\n",
        "                worksheet.write(row_number, col_number, value)\n",
        "    workbook.close()\n",
        "\n",
        "def query_search(query_id):\n",
        "    files = []\n",
        "    page_token = None\n",
        "    while True:\n",
        "        response = service.files().list(q=f\"'{query_id}' in parents\",\n",
        "                                        spaces='drive',\n",
        "                                        fields='files(id, name)').execute()\n",
        "        for file in response.get('files', []):\n",
        "            # Process change\n",
        "            file[\"name\"] = file['name'].lower().strip()\n",
        "        files.extend(response.get('files', []))\n",
        "        page_token = response.get('nextPageToken', None)\n",
        "        if page_token is None:\n",
        "            break\n",
        "    return files\n",
        "\n",
        "def download_gdrive_file(fileId):\n",
        "    request = service.files().get_media(fileId=fileId)\n",
        "    file = io.BytesIO()\n",
        "    downloader = MediaIoBaseDownload(file, request)\n",
        "    done = False\n",
        "    while done is False:\n",
        "      status, done = downloader.next_chunk()\n",
        "      print(f\"Download {int(status.progress() * 100)}.\")\n",
        "    return file\n",
        "\n",
        "def check_categories(coco_file):\n",
        "    cats = coco_file[\"categories\"]\n",
        "    cat_names = [i['name'].lower() for i in cats]\n",
        "    if 'coral_a' in cat_names:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def get_id(coco_file, current_image_name):\n",
        "    current_image_id = [i for i in coco_file['images'] if i['file_name'] == current_image_name][0][\"id\"]\n",
        "    return current_image_id\n",
        "\n",
        "def get_coco_annotations_for_image_id(coco_file, current_image_id):\n",
        "    annotations = [i for i in coco_file['annotations'] if i['image_id'] == current_image_id]\n",
        "    segmentations = [i['segmentation'] for i in annotations]\n",
        "    category_ids = [i[\"category_id\"] for i in annotations]\n",
        "    classes = [[i[\"name\"] for i in coco_file['categories'] if i[\"id\"] == j][0] for j in category_ids]\n",
        "    bboxes = create_bboxes_from_segs(segmentations)\n",
        "#     bboxes = [i['bbox'] for i in annotations]\n",
        "    areas = [i[\"area\"] for i in annotations]\n",
        "    return bboxes, segmentations, classes, areas\n",
        "\n",
        "def create_bboxes_from_segs(segs):\n",
        "    bboxes = []\n",
        "    for seg in segs:\n",
        "        xy = [(seg[0][idx*2], seg[0][idx*2+1]) for idx, i in enumerate(seg[0][0:-1:2])]\n",
        "        x0 = 10000000\n",
        "        y0 = 10000000\n",
        "        x1 = -1\n",
        "        y1 = -1\n",
        "        for point in xy:\n",
        "            if point[0]>x1:\n",
        "                x1 = point[0]\n",
        "            if point[0]<x0:\n",
        "                x0 = point[0]\n",
        "            if point[1]>y1:\n",
        "                y1 = point[1]\n",
        "            if point[1]<y0:\n",
        "                y0 = point[1]\n",
        "        bbox = [x0, y0, x1-x0, y1-y0]\n",
        "        bboxes.append(bbox)\n",
        "    return bboxes\n",
        "\n",
        "def change_bboxes(bboxes):\n",
        "    new_bboxes = []\n",
        "    for bbox in bboxes:\n",
        "        bbox[0] -= 100\n",
        "        bbox[1] -= 100\n",
        "        bbox[2] += 200\n",
        "        bbox[3] += 200\n",
        "        new_bboxes.append(bbox)\n",
        "    return new_bboxes\n",
        "\n",
        "def get_final_images_and_area(image, bboxes, segmentations, classes, areas):\n",
        "    # get image with masks\n",
        "    image_with_masks = layer_image_with_mask(image, segmentations)\n",
        "\n",
        "    # get cropped images\n",
        "    bbox_without_mask_images = []\n",
        "    bbox_with_mask_images = []\n",
        "    for bbox in bboxes:\n",
        "        cropped_image = crop_image(image, bbox)\n",
        "        bbox_without_mask_images.append(cropped_image)\n",
        "\n",
        "        cropped_image = crop_image(image_with_masks, bbox)\n",
        "        bbox_with_mask_images.append(cropped_image)\n",
        "\n",
        "    # get areas of all the corals\n",
        "    cm_2_areas = calculate_areas(classes, areas)\n",
        "\n",
        "    return bbox_without_mask_images, bbox_with_mask_images, cm_2_areas\n",
        "\n",
        "def crop_image(image, bbox):\n",
        "    x0, y0, w, h = bbox\n",
        "    cropped_image = image.crop((x0, y0, x0+w, y0+h))\n",
        "    return cropped_image\n",
        "\n",
        "def layer_image_with_mask(image, segmentations):\n",
        "    image = image.convert('RGBA')\n",
        "    image_copy = image.copy()\n",
        "    draw = ImageDraw.Draw(image_copy)\n",
        "\n",
        "    for seg in segmentations:\n",
        "        xy = [(seg[0][idx*2], seg[0][idx*2+1]) for idx, i in enumerate(seg[0][0:-1:2])]\n",
        "        draw.polygon(xy, fill = (255, 255, 0))\n",
        "    layered_image = Image.blend(image, image_copy, 0.5)\n",
        "    return layered_image\n",
        "\n",
        "\n",
        "def calculate_areas(classes, areas):\n",
        "    ref_idx = [idx for idx, i in enumerate(classes) if i.lower()=='ref'][0]\n",
        "    ref_area = areas[ref_idx]\n",
        "    cm_2_areas = [i * 25/ref_area for i in areas]\n",
        "    return cm_2_areas\n",
        "\n",
        "def sort_images(list_of_images, order):\n",
        "    array_images = [np.asarray(i) for i in list_of_images]\n",
        "    # array_images = np.array(array_images, dtype=object)[order]\n",
        "    # return [Image.fromarray(i.astype(np.uint8)) for i in array_images]\n",
        "    sorted_arrays = [x for _, x in sorted(zip(order, array_images), key=lambda pair: pair[0])]\n",
        "    return [Image.fromarray(i) for i in sorted_arrays]\n",
        "\n",
        "def resize_images(images_list):\n",
        "    size = (256, 256)\n",
        "    for i in images_list:\n",
        "        i.thumbnail(size)\n",
        "    return None"
      ],
      "metadata": {
        "id": "b7s8fJZ5rW-K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Custom Variables"
      ],
      "metadata": {
        "id": "6rrRz7F37snQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_dir_address = \"/content/drive/MyDrive/Projects/Coral Microfragmentation/Coral Monitoring/22-23 Season/\" #@param {type:\"string\"}\n",
        "date_name = \"\" #@param {type:\"string\"}\n",
        "intermediary_folder_path = \"\" #@param {type:\"string\"}\n",
        "table_number = 10 #@param {type:\"integer\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZVXijRS0sD7-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed Variables Being Defined and Running the Main Function"
      ],
      "metadata": {
        "id": "6EdI1eu_ASKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if date_name:\n",
        "    table_names = [\"table_\" + str(table_number)]\n",
        "    table_folder_addresses = [os.path.join(main_dir_address, date_name, intermediary_folder_path, table_names[0])]\n",
        "    save_file_name = \"Analysis-Excel\"\n",
        "    save_file_name_extension = save_file_name + '.xlsx'\n",
        "    save_file_path = os.path.join(table_folder_addresses[0], \"analysis_file\", save_file_name)\n",
        "    worksheet_names = [\"Main Analysis\"]\n",
        "else:\n",
        "    print('Create files across all dates for given table...')\n",
        "    table_names = [\"table_\" + str(table_number)] * len(ALL_DATE_NAMES)\n",
        "    table_folder_addresses = []\n",
        "    worksheet_names = []\n",
        "    for date_name in ALL_DATE_NAMES:\n",
        "        table_folder_addresses.append(\n",
        "            os.path.join(main_dir_address, date_name, intermediary_folder_path, table_names[0])\n",
        "        )\n",
        "        worksheet_names.append(f\"date_{date_name}\")\n",
        "    save_file_name = f\"Analysis-Excel_table_{str(table_number)}\"\n",
        "    save_file_name_extension = save_file_name + '.xlsx'\n",
        "    save_file_path = os.path.join(main_dir_address, \"analysis_files\", save_file_name)\n",
        "\n",
        "\n",
        "for idx, table_name in enumerate(table_names):\n",
        "    print(f'Progress: {(idx+1)/len(table_names)}')\n",
        "\n",
        "    table_folder_address = table_folder_addresses[idx]\n",
        "    worksheet_name = worksheet_names[idx]\n",
        "\n",
        "    # initialising some needed files and dictionary\n",
        "    pathlib.Path(\"/\".join(save_file_path.split(\"/\")[:-1])).mkdir(parents=True, exist_ok=True)\n",
        "    table_information_dict = dict()\n",
        "    table_information_dict[table_number] = {\"last_row\":0}\n",
        "    write_initial_header(save_file_path, worksheet_name)\n",
        "    add_information_for_specific_table(table_name, table_folder_address, date_name, table_information_dict, save_file_path, worksheet_name)"
      ],
      "metadata": {
        "id": "Rzp1IYKm8kj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef38f563-c53a-4325-d342-e8bd8ae4c001",
        "collapsed": true
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create files across all dates for given table...\n",
            "Progress: 0.16666666666666666\n",
            "COCO file found\n",
            "Progress: 0.3333333333333333\n",
            "COCO file found\n",
            "Progress: 0.5\n",
            "COCO file found\n",
            "Progress: 0.6666666666666666\n",
            "COCO file found\n",
            "Progress: 0.8333333333333334\n",
            "COCO file found\n",
            "Progress: 1.0\n",
            "COCO file found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rough"
      ],
      "metadata": {
        "id": "s4myWn-uuoVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialising some need files and dictionary\n",
        "\n",
        "table_information_dict = dict()\n",
        "for i in range(starting_table_number, ending_table_number+1):\n",
        "    table_information_dict[i] = {\"last_row\":0}\n",
        "    write_initial_header(\"Analysis-Excel\"+str(i))"
      ],
      "metadata": {
        "id": "OTys5aMK8K8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining custom variables\n",
        "dates_to_check = [\"22.12.7\", \"23.1.6\", \"23.2.6\", \"23.2.28\", \"23.4.9\", \"23.5.5\"]\n",
        "tables_to_check = [\"table_4\", \"table_5\", \"table_6\", \"table_7\", \"table_8\", \"table_9\", \"table_10\"]\n",
        "\n",
        "dates_to_check = [\"23.1.6\"]\n",
        "tables_to_check = [\"table_4\"]"
      ],
      "metadata": {
        "id": "r5iFJsoP7n2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monitoring_content = query_search(\"1fdjJD2nMX9V-8ddP4FjqpzoD-KnCI71P\")\n",
        "for date_folder in monitoring_content:\n",
        "    if date_folder['name'] in dates_to_check:\n",
        "\n",
        "        current_date_id = date_folder['id']\n",
        "        date_content = query_search(current_date_id)\n",
        "\n",
        "        date_content_names = [i[\"name\"] for i in date_content]\n",
        "        date_content_ids = [i[\"id\"] for i in date_content]\n",
        "        try:\n",
        "            idx_new_tables = date_content_names.index('new tables')\n",
        "            id_new_tables = date_content_ids[idx_new_tables]\n",
        "            new_table_content = query_search(id_new_tables)\n",
        "        except:\n",
        "            try:\n",
        "                idx_new_tables = date_content_names.index('coral tables')\n",
        "                id_new_tables = date_content_ids[idx_new_tables]\n",
        "                new_table_content = query_search(id_new_tables)\n",
        "                new_table_content = query_search([i[\"id\"] for i in new_table_content if i['name'] == 'new tables'][0])\n",
        "            except:\n",
        "                try:\n",
        "                    idx_new_tables = date_content_names.index('post cleaning')\n",
        "                    id_new_tables = date_content_ids[idx_new_tables]\n",
        "                    new_table_content = query_search(id_new_tables)\n",
        "                except:\n",
        "                    new_table_content = date_content\n",
        "        for table_folder in new_table_content:\n",
        "            if (table_folder[\"name\"] in tables_to_check) or (table_folder[\"name\"].replace(\" \", \"_\") in tables_to_check):\n",
        "                print(f\"---Checking for: Date-{date_folder['name']}, Table-{table_folder['name']}---\")\n",
        "                specific_table_content = query_search(table_folder['id'])"
      ],
      "metadata": {
        "id": "o80f-7Y77c6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monitoring_content = query_search(\"1fdjJD2nMX9V-8ddP4FjqpzoD-KnCI71P\")\n",
        "for date_folder in monitoring_content:\n",
        "    if date_folder['name'] in dates_to_check:\n",
        "\n",
        "        current_date_id = date_folder['id']\n",
        "        date_content = query_search(current_date_id)\n",
        "\n",
        "        date_content_names = [i[\"name\"] for i in date_content]\n",
        "        date_content_ids = [i[\"id\"] for i in date_content]\n",
        "        try:\n",
        "            idx_new_tables = date_content_names.index('new tables')\n",
        "            id_new_tables = date_content_ids[idx_new_tables]\n",
        "            new_table_content = query_search(id_new_tables)\n",
        "        except:\n",
        "            try:\n",
        "                idx_new_tables = date_content_names.index('coral tables')\n",
        "                id_new_tables = date_content_ids[idx_new_tables]\n",
        "                new_table_content = query_search(id_new_tables)\n",
        "                new_table_content = query_search([i[\"id\"] for i in new_table_content if i['name'] == 'new tables'][0])\n",
        "            except:\n",
        "                try:\n",
        "                    idx_new_tables = date_content_names.index('post cleaning')\n",
        "                    id_new_tables = date_content_ids[idx_new_tables]\n",
        "                    new_table_content = query_search(id_new_tables)\n",
        "                except:\n",
        "                    new_table_content = date_content\n",
        "        for table_folder in new_table_content:\n",
        "            if (table_folder[\"name\"] in tables_to_check) or (table_folder[\"name\"].replace(\" \", \"_\") in tables_to_check):\n",
        "                print(f\"---Checking for: Date-{date_folder['name']}, Table-{table_folder['name']}---\")\n",
        "                specific_table_content = query_search(table_folder['id'])\n",
        "\n",
        "                all_images = []\n",
        "                all_image_names = []\n",
        "                coco_file_found = False\n",
        "                for item in specific_table_content:\n",
        "\n",
        "                    potential_image = re.findall(\".*jpg|png\", item['name'])\n",
        "                    if len(potential_image)>0:\n",
        "                        image_name = potential_image[0]\n",
        "                        all_image_names.append(image_name)\n",
        "                        image_id = item['id']\n",
        "\n",
        "                        #download image\n",
        "                        file = download_gdrive_file(image_id)\n",
        "                        image = Image.open(io.BytesIO(file.getvalue()))\n",
        "                        image = ImageOps.exif_transpose(image)\n",
        "                        all_images.append(image)\n",
        "\n",
        "                    elif item['name'] == 'output':\n",
        "                        output_content = query_search(item[\"id\"])\n",
        "                        annotation_id = [i[\"id\"] for i in output_content if i[\"name\"]==\"annotation output\"][0]\n",
        "                        annotation_content = query_search(annotation_id)\n",
        "                        try:\n",
        "                            coco_file_id = [i[\"id\"] for i in annotation_content if \"coco\" in i[\"name\"]][0]\n",
        "                        except:\n",
        "                            print(f\"coco file not found for {date_folder['name']}, {table_folder['name']}\")\n",
        "                            break\n",
        "\n",
        "\n",
        "                        # download coco file\n",
        "                        file = download_gdrive_file(coco_file_id)\n",
        "                        coco_file = literal_eval(file.getvalue().decode(\"utf-8\"))\n",
        "                        bool_cat = check_categories(coco_file)\n",
        "                        coco_file_found = True\n",
        "                        if not bool_cat:\n",
        "                            print((\"Didn't find correct categories in COCO file of \"\n",
        "                                   f\"{date_folder['name']}-{table_folder['name']}\"))\n",
        "\n",
        "                if not coco_file_found:\n",
        "                    print(f\"coco file not found for {date_folder['name']}, {table_folder['name']}\")\n",
        "                    continue\n",
        "\n",
        "                sorting_order = np.argsort(all_image_names)\n",
        "                all_image_names = np.array(all_image_names)[sorting_order]\n",
        "                all_images = sort_images(all_images, sorting_order)\n",
        "\n",
        "\n",
        "                main_dict = {\n",
        "                    'date':[],\n",
        "                    'table':[],\n",
        "                    'tile':[],\n",
        "                    'name':[],\n",
        "                    'without_mask':[],\n",
        "                    'with_mask':[],\n",
        "                    'area':[]\n",
        "                }\n",
        "                # going into each image\n",
        "                print(\"Looping through all the image names now...\")\n",
        "                try:\n",
        "                    for idx, current_image_name in enumerate(all_image_names):\n",
        "                        current_image_id = get_id(coco_file, current_image_name)\n",
        "                        current_bboxes, current_segs, current_classes, current_areas = get_coco_annotations_for_image_id(coco_file, current_image_id)\n",
        "\n",
        "                        if not (\"ref\" in [i.lower() for i in current_classes]):\n",
        "                            print(f\"No ref label found for {date_folder['name']}, {table_folder['name']}\")\n",
        "                            break\n",
        "\n",
        "                        current_bboxes = change_bboxes(current_bboxes)\n",
        "                        without_mask_images, with_mask_images, areas = get_final_images_and_area(all_images[idx],\n",
        "                                                                                                 current_bboxes,\n",
        "                                                                                                 current_segs,\n",
        "                                                                                                 current_classes,\n",
        "                                                                                                 current_areas)\n",
        "                        resize_images(with_mask_images)\n",
        "                        resize_images(without_mask_images)\n",
        "                        for final_idx, _ in enumerate(current_classes):\n",
        "                            main_dict['date'].append(date_folder['name'])\n",
        "                            main_dict['table'].append(table_folder['name'])\n",
        "                            main_dict['tile'].append(idx+1)\n",
        "                            main_dict['name'].append(current_classes[final_idx])\n",
        "                            main_dict['without_mask'].append(without_mask_images[final_idx])\n",
        "                            main_dict['with_mask'].append(with_mask_images[final_idx])\n",
        "                            main_dict['area'].append(areas[final_idx])\n",
        "\n",
        "                    table_number = int(re.findall(\"\\d+\", table_folder[\"name\"])[0])\n",
        "\n",
        "                    last_row = table_information_dict[table_number][\"last_row\"]\n",
        "#                     last_row = main_dict_to_excel_openpyxl(main_dict,\n",
        "#                                                            last_row,\n",
        "#                                                            \"Jeremy_Analysis_\"+str(table_number))\n",
        "                    table_information_dict[table_number][\"last_row\"] = last_row\n",
        "\n",
        "                except Exception as e:\n",
        "                      print(\"\\nERROR:\", e, \"\\n\")"
      ],
      "metadata": {
        "id": "0rrIRBvPqOgs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}